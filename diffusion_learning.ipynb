{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we explore the application of Directed Acyclic Graph (DAG)-based Graph Neural Networks (GNNs) to learn a diffusion model over a DAG structure. The objective is to test whether different an architectures are capable of predicting the output signals given some sparse inputs. Leveraging the inherent structure of the DAG will play a fundamental role in the performance of the considered architectures.\n",
    "\n",
    "We investigate various settings to understand their impact on the diffusion process and prediction accuracy. These settings include:\n",
    "- The number of DAG-based Graph Signal Operators (GSOs) involved in the diffusion process.\n",
    "- The number of seeding nodes (sources) from which the diffusion starts.\n",
    "- The influence of selecting different transitive closures on the diffusion process.\n",
    "\n",
    "By experimenting with these settings, we aim to gain insights into how different configurations affect the performance and efficiency of the diffusion model. Ultimately, our goal is to develop an optimized architecture that can effectively capture and utilize the underlying structure of the DAG for accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import dgl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import src.dag_utils as dagu\n",
    "import src.utils as utils\n",
    "from src.arch import DAGConv, FB_DAGConv, SF_DAGConv\n",
    "from src.models import Model, LinDAGRegModel\n",
    "from src.baselines_archs import GCNN_2L, GCNN, GAT, MLP, MyGCNN, GraphSAGE, GIN\n",
    "\n",
    "import os\n",
    "\n",
    "# Ser random seed\n",
    "SEED = 10\n",
    "PATH = 'results/diffusion/'\n",
    "SAVE = True\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "dgl.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_per_process_memory_fraction(.5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default parameters and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2000\n",
    "\n",
    "data_p = {\n",
    "    'n_tries': 25,\n",
    "\n",
    "    ## Graph parameters\n",
    "    'p': 0.8,                    # Edge prob in Erdos-Renyi DAG\n",
    "    'N': 100,                    # Number of nodes\n",
    "\n",
    "    ## Signal parameters\n",
    "    'M': M,                   # Number of observed signals\n",
    "    'M_train': int(0.7 * M),  # Samples selected for training\n",
    "    'M_val': int(0.2 * M),    # Samples selected for validation\n",
    "    'M_test': int(0.1 * M),   # Samples selected for test\n",
    "    'src_t': 'constant',          # 'random' or 'constant'\n",
    "    'max_src_node': 15,           # Maximum index of nodes allowed to be sources\n",
    "    'n_sources': 5,              # Maximum Number of source nodes\n",
    "    'n_p': .05,                 # Normalized noise power\n",
    "    'max_GSO': 100,              # Maximum index of GSOs involved in the diffusion\n",
    "    'min_GSO': 50,               # Minimum index of GSOs involved in the diffusion\n",
    "    'n_GSOs': 25                 # Number of GSOs\n",
    "}\n",
    "\n",
    "# Model parameters\n",
    "default_arch_p = {\n",
    "    'in_dim': 1,        # Input dimension\n",
    "    'hid_dim': 16,     # Hidden dimension\n",
    "    'out_dim': 1,       # Output dimension\n",
    "    'L': 2,  # 3 also works well          # Number of layers\n",
    "    'l_act': None,\n",
    "}\n",
    "\n",
    "default_mod_p = {\n",
    "    'bs': 25,           # Size of the batch\n",
    "    'lr': 5e-4,         # Learning rate\n",
    "    'epochs': 50,       # Number of training epochs \n",
    "    'pat': 15,          # Number of non-decreasing epoch to stop training\n",
    "    'wd': 1e-4,         # Weight decay\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signals(d_p, GSOs):\n",
    "    range_GSO = np.arange(d_p['min_GSO'], d_p['max_GSO'])\n",
    "    gsos_idx = np.random.choice(range_GSO, size=d_p['n_GSOs'], replace=False)\n",
    "    sel_GSOs = GSOs[gsos_idx]\n",
    "    Y_t, X_t = dagu.create_diff_data(d_p['M'], sel_GSOs, d_p['max_src_node'], d_p['n_p'],\n",
    "                                         d_p['n_sources'], src_t=d_p['src_t'], torch_tensor=True)\n",
    "    \n",
    "    X_data = {'train': X_t[:d_p['M_train']], 'val': X_t[d_p['M_train']:-d_p['M_test']], 'test': X_t[-d_p['M_test']:]}\n",
    "    Y_data = {'train': Y_t[:d_p['M_train']], 'val': Y_t[d_p['M_train']:-d_p['M_test']], 'test': Y_t[-d_p['M_test']:]}\n",
    "    return X_data, Y_data, sel_GSOs\n",
    "\n",
    "def run_exps(exps, d_arc_p, d_mod_p, d_dat_p, GSOs, W, Adj, Psi=None, exp_desc='default'):\n",
    "    err_exps = np.zeros(len(exps))\n",
    "    std_exps = np.zeros(len(exps))\n",
    "    times_exps = np.zeros(len(exps))\n",
    "    for k, exp in enumerate(exps):\n",
    "        arc_p = {**d_arc_p, **exp['arc_p']}\n",
    "        mod_p = {**d_mod_p, **exp['mod_p']} if 'mod_p' in exp else d_mod_p\n",
    "        d_p = {**d_dat_p, **exp['dat_p']} if 'dat_p' in exp else d_dat_p\n",
    "\n",
    "        X_data, Y_data, sel_GSOs = get_signals(d_p, GSOs)\n",
    "\n",
    "        if exp['arc_p']['arch'] == LinDAGRegModel:\n",
    "            lin_model = LinDAGRegModel(W, Psi)\n",
    "            t_i = time.time()\n",
    "            lin_model.fit(X_data['train'], Y_data['train'])\n",
    "            t_e = time.time() - t_i\n",
    "\n",
    "            err_exps[k], std_exps[k] = lin_model.test(X_data['test'], Y_data['test'])\n",
    "        else:\n",
    "            GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
    "            K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0  \n",
    "            arch = utils.instantiate_arch(arc_p, K)\n",
    "            model = Model(arch, device=device)\n",
    "\n",
    "            t_i = time.time()\n",
    "            model.fit(X_data, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'],\n",
    "                    patience=mod_p['pat'])\n",
    "            t_e = time.time() - t_i\n",
    "\n",
    "            err_exps[k], std_exps[k] = model.test(X_data['test'], Y_data['test'], GSO)\n",
    "        times_exps[k] = t_e\n",
    "        print(f'\\t-{exp_desc}. {exp[\"leg\"]}: err: {err_exps[k]:.3f} - time: {times_exps[k]:.1f}')\n",
    "\n",
    "    return err_exps, std_exps, times_exps\n",
    "\n",
    "def run_exp(d_p, d_arc_p, d_mod_p, exps):\n",
    "    err = np.zeros((d_p['n_tries'], len(exps)))\n",
    "    std = np.zeros((d_p['n_tries'], len(exps)))\n",
    "    times = np.zeros((d_p['n_tries'], len(exps)))\n",
    "\n",
    "    t_begin = time.time()\n",
    "    for i in range(d_p['n_tries']):\n",
    "        Adj, W, GSOs, Psi = utils.get_graph_data(d_p, get_Psi=True)\n",
    "        X_data, Y_data, sel_GSOs = get_signals(d_p, GSOs)\n",
    "        \n",
    "        for j, exp in enumerate(exps):\n",
    "            arc_p = {**d_arc_p, **exp['arc_p']}\n",
    "            mod_p = {**d_mod_p, **exp['mod_p']} if 'mod_p' in exp.keys() else d_mod_p\n",
    "\n",
    "            if exp['arc_p']['arch'] == LinDAGRegModel:\n",
    "                lin_model = LinDAGRegModel(W, Psi)\n",
    "                t_i = time.time()\n",
    "                lin_model.fit(X_data['train'], Y_data['train'])\n",
    "                t_e = time.time() - t_i\n",
    "\n",
    "                err[i,j], std[i,j] = lin_model.test(X_data['test'], Y_data['test'])\n",
    "            else:\n",
    "                GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
    "\n",
    "                K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0  \n",
    "                arch = utils.instantiate_arch(arc_p, K)\n",
    "                model = Model(arch, device=device)\n",
    "\n",
    "                t_i = time.time()\n",
    "                model.fit(X_data, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'],\n",
    "                        patience=mod_p['pat'])\n",
    "                t_e = time.time() - t_i\n",
    "                err[i,j], std[i,j] = model.test(X_data['test'], Y_data['test'], GSO)\n",
    "\n",
    "            times[i,j] = t_e\n",
    "\n",
    "            print(f'-{i}. {exp[\"leg\"]}: err: {err[i,j]:.3f} - time: {times[i,j]:.1f}')\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting err: 0.013205729816744602\n",
      "-0. Linear: err: 0.013 - time: 0.3\n",
      "-0. FB-DAGCNN-Prior: err: 0.014 - time: 4.3\n",
      "fitting err: 0.023384105033098766\n",
      "-1. Linear: err: 0.022 - time: 0.3\n",
      "-1. FB-DAGCNN-Prior: err: 0.018 - time: 3.9\n",
      "fitting err: 0.014190164661681711\n",
      "-2. Linear: err: 0.015 - time: 0.3\n",
      "-2. FB-DAGCNN-Prior: err: 0.015 - time: 3.6\n",
      "fitting err: 0.01736224682776876\n",
      "-3. Linear: err: 0.018 - time: 0.3\n",
      "-3. FB-DAGCNN-Prior: err: 0.024 - time: 3.7\n",
      "fitting err: 0.12625487445952224\n",
      "-4. Linear: err: 0.127 - time: 0.3\n",
      "-4. FB-DAGCNN-Prior: err: 0.123 - time: 3.2\n",
      "----- Ellapsed time: 0.37 minutes -----\n"
     ]
    }
   ],
   "source": [
    "# Experiments to be run\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': LinDAGRegModel}, 'leg': 'Linear'},\n",
    "\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'mod_p': {}, 'leg': 'DAGCNN'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'sel_GSOs'}, 'mod_p': {}, 'leg': 'DAGCNN-Prior'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, 'leg': 'DAGCNN-Rnd-5'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'mod_p': {}, 'leg': 'DAGCNN-Rnd-15'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'mod_p': {}, 'leg': 'FB-DAGCNN'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'mod_p': {}, 'leg': 'FB-DAGCNN-Prior'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, 'leg': 'FB-DAGCNN-Rnd-5'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'mod_p': {}, 'leg': 'FB-DAGCNN-Rnd-15'},\n",
    "\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'mod_p': {}, 'leg': 'My-GNN-A'},\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'W'}, 'mod_p': {}, 'leg': 'My-GNN-W'},\n",
    "\n",
    "    {'arc_p': {'arch': GAT, 'GSO': 'A-dgl', 'n_heads': 2, 'hid_dim': 16, 'gat_params': {'attn_drop': 0}},\n",
    "     'mod_p': {}, 'leg': 'GAT-A'},\n",
    "    {'arc_p': {'arch': GraphSAGE, 'GSO': 'A-dgl', 'hid_dim': 16, 'agg': 'mean'}, 'leg': 'GraphSAGE-A'},\n",
    "    {'arc_p': {'arch': GIN, 'GSO': 'A-dgl', 'hid_dim': 16, 'agg': 'sum'}, 'leg': 'GIN-A'},\n",
    "    {'arc_p': {'arch': MLP, 'GSO': None}, 'mod_p': {}, 'leg': 'MLP'},    \n",
    "    ]\n",
    "\n",
    "err, std, times = run_exp(data_p, default_arch_p, default_mod_p, Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED FILE: results/diffusion/init_exp-constant\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>Mean Err</th>\n",
       "      <th>Median Err</th>\n",
       "      <th>Mean Std</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>0.337272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FB-DAGCNN-Prior</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.017654</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>3.736161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Exp  Mean Err  Median Err  Mean Std      time\n",
       "0           Linear  0.038896    0.017966  0.018487  0.337272\n",
       "1  FB-DAGCNN-Prior  0.038800    0.017654  0.015658  3.736161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEFAULT PARAMETERS\n",
    "if SAVE:\n",
    "    file_name = PATH + f'init_exp-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "leg = [exp['leg'] for exp in Exps]\n",
    "utils.display_data(leg, err, std, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of selected GSOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_gso_exp(d_dat_p, d_arc_p, d_mod_p, N_GSOs, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    t_begin = time.time()\n",
    "\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Iteration:', i)\n",
    "\n",
    "        Adj, W, GSOs = utils.get_graph_data(d_dat_p)\n",
    "\n",
    "        for j, n_gsos in enumerate(N_GSOs):\n",
    "            data_params_aux = dict(d_dat_p)\n",
    "            data_params_aux['n_GSOs'] = n_gsos\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, d_arc_p, d_mod_p, data_params_aux, GSOs, W, Adj)\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "    return err, std, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exps = [\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 100}, 'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'DAGCNN, All', 'fmt': 'v-'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 100}, 'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5},\n",
    "     'mod_p': {}, 'leg': 'DAGCNN-Rnd-5, All', 'fmt': '^-'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 100}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'FB-DAGCNN, All', 'fmt': 'o-'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 100}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5},\n",
    "     'mod_p': {}, 'leg': 'FB-DAGCNN-Rnd-5, All', 'fmt': 's-'},\n",
    "\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 50}, 'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'DAGCNN, Firsts', 'fmt': 'v--'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 50}, 'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, \n",
    "     'leg': 'DAGCNN-Rnd, Firsts', 'fmt': '^--'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 50}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'FB-DAGCNN, Firsts', 'fmt': 'o--'},\n",
    "    {'dat_p': {'min_GSO': 0, 'max_GSO': 50}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5},\n",
    "     'mod_p': {}, 'leg': 'FB-DAGCNN-Rnd, Firsts', 'fmt': 's--'},\n",
    "\n",
    "    {'dat_p': {'min_GSO': 50, 'max_GSO': 100}, 'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'DAGCNN, Lasts', 'fmt': 'v:'},\n",
    "    {'dat_p': {'min_GSO': 50, 'max_GSO': 100}, 'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, \n",
    "     'leg': 'DAGCNN-Rnd, Lasts', 'fmt': '^:'},\n",
    "    {'dat_p': {'min_GSO': 50, 'max_GSO': 100}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'mod_p': {},\n",
    "     'leg': 'FB-DAGCNN, Lasts', 'fmt': 'o:'},\n",
    "    {'dat_p': {'min_GSO': 50, 'max_GSO': 100}, 'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'mod_p': {},\n",
    "     'leg': 'FB-DAGCNN-Rnd, Lasts', 'fmt': 's:'},\n",
    "    ]\n",
    "\n",
    "N_GSOs = np.arange(5, 41, 5)\n",
    "\n",
    "err, std, times = influence_gso_exp(data_p, default_arch_p, default_mod_p, N_GSOs, Exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'gso_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_GSOs)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "\n",
    "skip_idx = [2, 3, 6, 7, 10, 11]\n",
    "utils.plot_results(med_err, N_GSOs, Exps, 'Number of GSOs involved in the filter',\n",
    "                   skip_idx=skip_idx, n_cols=3)\n",
    "\n",
    "skip_idx = [0, 1, 4, 5, 8, 9]\n",
    "utils.plot_results(med_err, N_GSOs, Exps, 'Number of GSOs involved in the filter',\n",
    "                   skip_idx=skip_idx, n_cols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'gso_inf-constant.npz'\n",
    "# err, std, times, Exps, N_sources = utils.load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of the number of source nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_sources_exp(d_dat_p, d_arc_p, d_mod_p, N_sources, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(N_sources), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(N_sources), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(N_sources), len(exps)))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Iteration:', i)\n",
    "\n",
    "        Adj, W, GSOs = utils.get_graph_data(d_dat_p)\n",
    "\n",
    "        for j, n_sources in enumerate(N_sources):\n",
    "            data_params_aux = dict(d_dat_p)\n",
    "            data_params_aux['n_sources'] = n_sources\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, d_arc_p, d_mod_p, data_params_aux, GSOs, W,\n",
    "                                                      Adj, exp_desc=str(n_sources))\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2000\n",
    "data_soruces = dict(data_p)\n",
    "data_soruces['max_src_node'] = 25\n",
    "\n",
    "N_sources = [1, 5, 10, 15, 20, 25]\n",
    "\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'mod_p': {}, 'leg': 'DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'sel_GSOs'}, 'mod_p': {}, 'leg': 'DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, 'leg': 'DAGCNN-Rnd', 'fmt': 's-'},\n",
    "\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'mod_p': {}, 'leg': 'FB-DAGCNN', 'fmt': 'o--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'mod_p': {}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'mod_p': {}, 'leg': 'FB-DAGCNN-Rnd', 'fmt': 's--'},\n",
    "\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'mod_p': {}, 'leg': 'GNN-A', 'fmt': 'v:'},\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'W'}, 'mod_p': {}, 'leg': 'GNN-W', 'fmt': '^:'},\n",
    "    {'arc_p': {'arch': MLP, 'GSO': None}, 'mod_p': {}, 'leg': 'MLP', 'fmt': '>:'},\n",
    "    ]\n",
    "\n",
    "err, std, times = influence_sources_exp(data_soruces, default_arch_p, default_mod_p, N_sources, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'src_nodes_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_sources)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "utils.plot_results(med_err, N_sources, Exps, 'Number of soruce nodes', ylim_bottom=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'src_nodes_inf-constant.npz'\n",
    "# err, std, times, Exps, N_sources = utils.load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of randomly selected GSOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_selected_gsp_exp(d_dat_p, d_arc_p, d_mod_p, N_GSOs, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(N_GSOs), len(exps)))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Realization:', i)\n",
    "\n",
    "        Adj, W, GSOs = utils.get_graph_data(d_dat_p)\n",
    "\n",
    "        for j, n_gsos in enumerate(N_GSOs):\n",
    "            arch_params_aux = dict(d_arc_p)\n",
    "            arch_params_aux['n_gsos'] = n_gsos\n",
    "\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, arch_params_aux, d_mod_p, d_dat_p, GSOs, W,\n",
    "                                                      Adj, exp_desc=str(n_gsos))\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generated with last GSOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2000\n",
    "N_GSOs = [5, 10, 15, 20, 25, 30, 45, 50, 55, 60]\n",
    "\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs'}, 'leg': 'DAGCNN-Rnd', 'fmt': 's-'},\n",
    "\n",
    "\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'first_GSOs'}, 'leg': 'FB-DAGCNN-first', 'fmt': 'v--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'last_GSOs'}, 'leg': 'FB-DAGCNN-last', 'fmt': '^--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs'}, 'leg': 'FB-DAGCNN-Rnd', 'fmt': 's--'},\n",
    "]\n",
    "\n",
    "err, std, times = influence_selected_gsp_exp(data_p, default_arch_p, default_mod_p, N_GSOs, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'sel_gso_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_GSOs)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "mean_time = times.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "med_time = np.median(times, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "utils.plot_results(med_err, N_GSOs, Exps, 'Number of sel GSOs', n_cols=2)\n",
    "utils.plot_results(med_time, N_GSOs, Exps, 'Number of sel GSOs', ylabel='Mean time (seg)', n_cols=2,\n",
    "                   logy=False, ylim_bottom=1, ylim_top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generated with all GSOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rnd_gsos = dict(data_p)\n",
    "data_rnd_gsos['min_GSO'] = 0\n",
    "data_rnd_gsos['max_GSO'] = 100\n",
    "\n",
    "M = 2000\n",
    "N_GSOs = [5, 10, 15, 20, 25, 30, 45, 50, 55, 60]\n",
    "\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs'}, 'leg': 'DAGCNN-Rnd', 'fmt': 's-'},\n",
    "\n",
    "\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'first_GSOs'}, 'leg': 'FB-DAGCNN-first', 'fmt': 'v--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'last_GSOs'}, 'leg': 'FB-DAGCNN-last', 'fmt': '^--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs'}, 'leg': 'FB-DAGCNN-Rnd', 'fmt': 's--'},\n",
    "]\n",
    "\n",
    "err, std, times = influence_selected_gsp_exp(data_rnd_gsos, default_arch_p, default_mod_p, N_GSOs, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'sel_gso_inf-from_all_gso-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_GSOs)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "mean_time = times.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "med_time = np.median(times, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "utils.plot_results(med_err, N_GSOs, Exps, 'Number of sel GSOs', n_cols=2)\n",
    "utils.plot_results(med_time, N_GSOs, Exps, 'Number of sel GSOs', ylabel='Mean time (seg)', n_cols=2,\n",
    "                   logy=False, ylim_bottom=1, ylim_top=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'sel_gso_inf-constant.npz'\n",
    "# err, std, times, Exps, N_GSOs = utils.load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_n_layers_exp(d_dat_p, d_arc_p, d_mod_p, N_layers, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(N_layers), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(N_layers), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(N_layers), len(exps)))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Realization:', i)\n",
    "\n",
    "        Adj, W, GSOs = utils.get_graph_data(d_dat_p)\n",
    "\n",
    "        for j, n_layers in enumerate(N_layers):\n",
    "            arch_params_aux = dict(d_arc_p)\n",
    "            arch_params_aux['L'] = n_layers\n",
    "\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, arch_params_aux, d_mod_p, d_dat_p, GSOs, W,\n",
    "                                                      Adj, exp_desc=str(n_layers))\n",
    "\n",
    "            err[i,j][err[i,j] > 1] = 1\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_layers = np.arange(1,7)\n",
    "\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 25}, 'leg': 'DAGCNN-Rnd-25',\n",
    "     'fmt': 's-'},\n",
    "    {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'DAGCNN-Rnd-10',\n",
    "     'fmt': 'x-'},\n",
    "\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 25}, 'leg': 'FB-DAGCNN-Rnd-25',\n",
    "     'fmt': 's--'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'FB-DAGCNN-Rnd-10',\n",
    "     'fmt': 'x--'}, \n",
    "\n",
    "    {'arc_p': {'arch': SF_DAGConv, 'GSO': 'GSOs'}, 'leg': 'SF-DAGCNN', 'fmt': '<:'},\n",
    "\n",
    "\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'leg': 'GNN-A', 'fmt': 'v:'},\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'W'}, 'leg': 'GNN-W',  'fmt': '^:'},\n",
    "    {'arc_p': {'arch': MLP, 'GSO': None}, 'leg': 'MLP',  'fmt': '>:'},\n",
    "]\n",
    "\n",
    "err, std, times = influence_n_layers_exp(data_p, default_arch_p, default_mod_p, N_layers, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'n_layers_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_layers)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "mean_time = times.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "skip_idx = [8, 9, 10, 11]\n",
    "utils.plot_results(mean_err, N_layers, Exps, 'Number of layers', skip_idx=skip_idx, n_cols=2)\n",
    "utils.plot_results(mean_time, N_layers, Exps, 'Number of layer', ylabel='Mean time (seg)',\n",
    "                   skip_idx=skip_idx, n_cols=2, ylim_bottom=1, ylim_top=50)\n",
    "\n",
    "skip_idx = [0, 1, 2, 3]\n",
    "utils.plot_results(mean_err, N_layers, Exps, 'Number of layers', skip_idx=skip_idx, n_cols=2)\n",
    "utils.plot_results(mean_time, N_layers, Exps, 'Number of layer', ylabel='Mean time (seg)',\n",
    "                   skip_idx=skip_idx, n_cols=2, ylim_bottom=1, ylim_top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'n_layers_inf-constant.npz'\n",
    "# err, std, times, Exps, N_layers = utils.load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the density of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_graph_density(d_dat_p, d_arc_p, d_mod_p, P_values, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(P_values), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(P_values), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(P_values), len(exps)))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Realization:', i)\n",
    "\n",
    "        for j, p in enumerate(P_values):\n",
    "            data_params_aux = dict(d_dat_p)\n",
    "            data_params_aux['p'] = p            \n",
    "            Adj, W, GSOs = utils.get_graph_data(data_params_aux)\n",
    "\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, d_arc_p, d_mod_p, data_params_aux, GSOs, W,\n",
    "                                                      Adj, exp_desc=str(p))\n",
    "\n",
    "            err[i,j][err[i,j] > 1] = 1\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_values = [.1, .2, .3, .4, .5, .6, .7, .8]\n",
    "\n",
    "Exps = [\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 25}, 'leg': 'FB-DAGCNN-Rnd-25',\n",
    "     'fmt': 's-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'FB-DAGCNN-Rnd-10',\n",
    "     'fmt': 'x-'}, \n",
    "\n",
    "    # {'arc_p': {'arch': SF_DAGConv, 'GSO': 'GSOs'}, 'leg': 'SF-DAGCNN', 'fmt': '<:'},\n",
    "\n",
    "\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'leg': 'GNN-A', 'fmt': 'v:'},\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'W'}, 'leg': 'GNN-W',  'fmt': '^:'},\n",
    "    {'arc_p': {'arch': MLP, 'GSO': None}, 'leg': 'MLP',  'fmt': '>:'},\n",
    "]\n",
    "\n",
    "err, std, times = influence_graph_density(data_p, default_arch_p, default_mod_p, P_values, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'density_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=P_values)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "mean_time = times.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "utils.plot_results(mean_err, P_values, Exps, 'p', skip_idx=[], n_cols=2)\n",
    "# utils.plot_results(mean_time, N_nodes, Exps, 'Number of layer', ylabel='Mean time (seg)',\n",
    "#                    skip_idx=skip_idx, n_cols=2, ylim_bottom=1, ylim_top=50)\n",
    "\n",
    "utils.plot_results(med_err, P_values, Exps, 'Number of layers', skip_idx=[], n_cols=2,\n",
    "                   ylabel='Median err')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'n_layers_inf-constant.npz'\n",
    "# err, std, times, Exps, N_layers = utils.load_data(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the size of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_graph_size(d_dat_p, d_arc_p, d_mod_p, N_nodes, exps):\n",
    "    err = np.zeros((d_dat_p['n_tries'], len(N_nodes), len(exps)))\n",
    "    std = np.zeros((d_dat_p['n_tries'], len(N_nodes), len(exps)))\n",
    "    times = np.zeros((d_dat_p['n_tries'], len(N_nodes), len(exps)))\n",
    "    \n",
    "    t_begin = time.time()\n",
    "    for i in range(d_dat_p['n_tries']):\n",
    "        print('Realization:', i)\n",
    "\n",
    "        for j, n_nodes in enumerate(N_nodes):\n",
    "            data_params_aux = dict(d_dat_p)\n",
    "            data_params_aux['N'] = n_nodes\n",
    "            # Always use second half of nodes to generate data\n",
    "            data_params_aux['max_GSO'] = n_nodes\n",
    "            data_params_aux['min_GSO'] = int(n_nodes/2)\n",
    "            available_nodes = data_params_aux['max_GSO'] - data_params_aux['min_GSO']\n",
    "            data_params_aux['n_GSOs'] = min(d_dat_p['n_GSOs'], available_nodes)\n",
    "\n",
    "            Adj, W, GSOs = utils.get_graph_data(data_params_aux)\n",
    "\n",
    "            err[i,j], std[i,j], times[i,j] = run_exps(exps, d_arc_p, d_mod_p, data_params_aux, GSOs, W,\n",
    "                                                      Adj, exp_desc=str(Adj.shape[0]))\n",
    "\n",
    "            err[i,j][err[i,j] > 1] = 1\n",
    "\n",
    "    total_t = (time.time() - t_begin)/60\n",
    "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
    "\n",
    "    return err, std, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_nodes = [25, 50, 100, 200, 400]\n",
    "\n",
    "Exps = [\n",
    "\n",
    "    # {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o--'},\n",
    "\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'FB-DAGCNN', 'fmt': 'o-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'sel_GSOs'}, 'leg': 'FB-DAGCNN-Prior', 'fmt': 'P-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 25}, 'leg': 'FB-DAGCNN-Rnd-25',\n",
    "     'fmt': 's-'},\n",
    "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'FB-DAGCNN-Rnd-10',\n",
    "     'fmt': 'x-'}, \n",
    "\n",
    "    # {'arc_p': {'arch': SF_DAGConv, 'GSO': 'GSOs'}, 'leg': 'SF-DAGCNN', 'fmt': '<:'},\n",
    "\n",
    "\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'leg': 'GNN-A', 'fmt': 'v:'},\n",
    "    {'arc_p': {'arch': MyGCNN, 'GSO': 'W'}, 'leg': 'GNN-W',  'fmt': '^:'},\n",
    "    {'arc_p': {'arch': MLP, 'GSO': None}, 'leg': 'MLP',  'fmt': '>:'},\n",
    "]\n",
    "\n",
    "err, std, times = influence_graph_size(data_p, default_arch_p, default_mod_p, N_nodes, Exps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    file_name = PATH + f'n_nodes_inf-{data_p[\"src_t\"]}'\n",
    "    np.savez(file_name, err=err, std=std, times=times, exp=Exps, xvals=N_nodes)\n",
    "    print('SAVED FILE:', file_name)\n",
    "\n",
    "mean_err = err.mean(axis=0)\n",
    "mean_time = times.mean(axis=0)\n",
    "med_err = np.median(err, axis=0)\n",
    "legend = [exp['leg'] for exp in Exps]\n",
    "utils.plot_results(mean_err, N_nodes, Exps, 'Number of nodes', skip_idx=[], n_cols=2)\n",
    "utils.plot_results(mean_time, N_nodes, Exps, 'Number of nodes', ylabel='Mean time (seg)',\n",
    "                   skip_idx=[], n_cols=2, ylim_bottom=1, ylim_top=50)\n",
    "\n",
    "utils.plot_results(med_err, N_nodes, Exps, 'Number of nodes', skip_idx=[], n_cols=2)\n",
    "utils.plot_results(mean_time, N_nodes, Exps, 'Number of nodes', ylabel='Mean time (seg)',\n",
    "                   skip_idx=[], n_cols=2, ylim_bottom=1, ylim_top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = PATH + 'n_layers_inf-constant.npz'\n",
    "# err, std, times, Exps, N_layers = utils.load_data(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
