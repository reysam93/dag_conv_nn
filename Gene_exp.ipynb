{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6NnQNvgfyzO",
        "outputId": "a4ee07e5-d00b-4c0e-e175-233078f99b73"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch==2.6.0 torchaudio torchvision torch-scatter torch-sparse torch-cluster torch-spline-conv -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2rS_38s9BxU",
        "outputId": "d7fb5349-bf4c-47b8-b9f0-cb377750884e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.4.0\n",
            "Uninstalling torch-2.4.0:\n",
            "  Successfully uninstalled torch-2.4.0\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torch_scatter 2.1.2+pt24cu121\n",
            "Uninstalling torch_scatter-2.1.2+pt24cu121:\n",
            "  Successfully uninstalled torch_scatter-2.1.2+pt24cu121\n",
            "Found existing installation: torch_sparse 0.6.18+pt24cu121\n",
            "Uninstalling torch_sparse-0.6.18+pt24cu121:\n",
            "  Successfully uninstalled torch_sparse-0.6.18+pt24cu121\n",
            "\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchaudio torchvision torch-scatter torch-sparse torch-cluster torch-spline-conv -y\n",
        "!pip install torch==2.4.0+cu121  --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "TwQOBMNI9EoA",
        "outputId": "2fed11c5-a171-4691-ba93-4366eeb79011"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-spline-conv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0+cu121\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp311-cp311-linux_x86_64.whl (799.1 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0+cu121) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0+cu121) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0+cu121) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0+cu121) (1.3.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.4.0+cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "945501662d2e4529b175898b9ba24f0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xsXE7DkN9HWf",
        "outputId": "1b79f4e8-9484-4009-a7cd-d11648f58a6a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.4.0+cu121)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cu121\n",
            "    Uninstalling torch-2.4.0+cu121:\n",
            "      Successfully uninstalled torch-2.4.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dgl 2.4.0+cu124 requires torch<=2.4.0, but you have torch 2.6.0+cu124 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "4eee170fe9d442d589ad70ab7580dbd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall dgl -y\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3CRs8dhj9KHR",
        "outputId": "0d983818-83cf-4d1c-8dfc-e50ac157fc5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dgl 2.4.0+cu124\n",
            "Uninstalling dgl-2.4.0+cu124:\n",
            "  Successfully uninstalled dgl-2.4.0+cu124\n",
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html\n",
            "Collecting dgl\n",
            "  Using cached https://data.dgl.ai/wheels/torch-2.4/cu124/dgl-2.4.0%2Bcu124-cp311-cp311-manylinux1_x86_64.whl (347.8 MB)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from dgl) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Collecting torch<=2.4.0 (from dgl)\n",
            "  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->dgl) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<=2.4.0->dgl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch<=2.4.0->dgl)\n",
            "  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.4.127)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dgl) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, dgl\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dgl-2.4.0+cu124 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 triton-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dgl",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "8048500ca58849f58c74008aa9344c05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
        "!pip install torch-geometric\n",
        "!pip install igraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "LJqmSh8L9Kth",
        "outputId": "77630f56-4ca3-45eb-85c0-d2e0f3e01046"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (10.9 MB)\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt24cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch_scatter"
                ]
              },
              "id": "8c38765457f444e29f1025d1673e278a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Using cached https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp311-cp311-linux_x86_64.whl (5.1 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt24cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch_sparse"
                ]
              },
              "id": "d8d6a36f0c414c6e9832a3c46676d3f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.11/dist-packages (0.11.8)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from igraph) (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0zCe-EMH3FE",
        "outputId": "13e5da3a-33ad-4f97-fc43-a1885633e567"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 21:33:47 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmU5Lr550tqp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "import networkx as nx\n",
        "from tqdm.auto import tqdm\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "from numpy import linalg as la\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import src.dag_utils as dagu\n",
        "import src.utils as utils\n",
        "from src.arch import DAGConv, FB_DAGConv, SF_DAGConv, ADCN , ParallelMLPSum, SharedMLPSum, SMLP, SAM1\n",
        "from src.models import Model, LinDAGRegModel\n",
        "from src.baselines_archs import GAT, MLP, MyGCNN, GraphSAGE, GIN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"dgl\")\n",
        "import os\n",
        "import igraph as ig\n",
        "from src.utils_Dagnn import *\n",
        "from src.DAGNN import DAGNN, DVAE\n",
        "\n",
        "\n",
        "\n",
        "# Ser random seed\n",
        "SEED = 10\n",
        "PATH = 'results/diffusion/'\n",
        "SAVE = True\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "# dgl.random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# torch.cuda.set_per_process_memory_fraction(.5, device=device)\n",
        "\n",
        "\n",
        "\n",
        "M = 22\n",
        "\n",
        "data_p = {\n",
        "    'n_tries': 25,  #25,\n",
        "\n",
        "    ## Graph parameters\n",
        "    'p': 0.2,  # .2                  # Edge prob in Erdos-Renyi DAG\n",
        "    'N': 107,                    # Number of nodes\n",
        "\n",
        "    ## Signal parameters\n",
        "    'M': M,                   # Number of observed signals\n",
        "    'M_train': int(0.7 * M),  # Samples selected for training\n",
        "    'M_val': int(0.2 * M),    # Samples selected for validation\n",
        "    'M_test': int(0.1 * M),   # Samples selected for test\n",
        "    'src_t': 'constant',          # 'random' or 'constant'\n",
        "    'max_src_node': 15, #25,           # Maximum index of nodes allowed to be sources\n",
        "    'n_sources': 14,             # Maximum Number of source nodes\n",
        "    'n_p_x': .1,\n",
        "    'n_p_y': .1,                 # Normalized noise power\n",
        "    'max_GSO': 50,              # Maximum index of GSOs involved in the diffusion\n",
        "    'min_GSO': 0,               # Minimum index of GSOs involved in the diffusion\n",
        "    'n_GSOs': 20,            # Number of GSOs\n",
        "}\n",
        "\n",
        "default_mod_p = {\n",
        "    'bs': 5,           # Size of the batch\n",
        "    'lr': 5e-3,         # Learning rate. 5e-3\n",
        "    'epochs': 500,  #50,       # Number of training epochs\n",
        "    'pat': 25,  # 15        # Number of non-decreasing epoch to stop training\n",
        "    'wd': 1e-4,         # Weight decay\n",
        "}\n",
        "\n",
        "default_arch_args = {\n",
        "    'in_dim': 1,        # Input dimension\n",
        "    'hid_dim': 32,     # Hidden dimension\n",
        "    'out_dim': 1,       # Output dimension\n",
        "    'n_layers': 2,#2,  # 3 also works well          # Number of layers\n",
        "    'l_act': None,\n",
        "    'bias': True,\n",
        "}\n",
        "\n",
        "\n",
        "def add_noise(signal, n_p):\n",
        "    shape = signal.shape\n",
        "\n",
        "    M = shape[0]\n",
        "    N = shape[1]\n",
        "\n",
        "    if n_p <= 0:\n",
        "        return signal\n",
        "\n",
        "    signal_norm = torch.norm(signal, p=2, dim=1, keepdim=True)\n",
        "    signal_norm[signal_norm == 0] = 1\n",
        "    noise = torch.randn(M, N, 1, device=signal.device)\n",
        "    noise_norm = torch.norm(noise, p=2, dim=1, keepdim=True)\n",
        "    noise = noise * signal_norm * torch.sqrt(torch.tensor(n_p)) / noise_norm\n",
        "\n",
        "    return signal + noise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_real_data(d_dat_p ,get_Psi=False):\n",
        "\n",
        "    Adj = np.load('/content/drive/MyDrive/Gene/A_gene.npy')\n",
        "\n",
        "    W = la.inv(np.eye(d_dat_p['N']) - Adj)\n",
        "    W_inf = la.inv(W)\n",
        "    dag = nx.from_numpy_array(Adj.T, create_using=nx.DiGraph())\n",
        "    if get_Psi:\n",
        "        Psi = np.array([dagu.compute_Dq(dag, i, d_dat_p['N']) for i in range(d_dat_p['N'])]).T\n",
        "        GSOs = np.array([(W * Psi[:,i]) @ W_inf for i in range(d_dat_p['N'])])\n",
        "        return Adj, W, GSOs, Psi\n",
        "\n",
        "    GSOs = np.array([(W * dagu.compute_Dq(dag, i, d_dat_p['N'])) @ W_inf for i in range(d_dat_p['N'])])\n",
        "\n",
        "\n",
        "\n",
        "    return Adj, W, GSOs\n",
        "\n",
        "\n",
        "\n",
        "def arth(d_p, GSOs):\n",
        "\n",
        "    range_GSO = np.arange(d_p['min_GSO'], d_p['max_GSO'])\n",
        "    gsos_idx = np.random.choice(range_GSO, size=d_p['n_GSOs'], replace=False)\n",
        "    sel_GSOs = GSOs[gsos_idx]\n",
        "    Y = torch.from_numpy(np.load('/content/drive/MyDrive/Gene/filtered_expression_data.npy')).float()\n",
        "\n",
        "    X = Y.clone()\n",
        "    X = X.unsqueeze(2)\n",
        "    Y = Y.unsqueeze(2)\n",
        "    m = 70\n",
        "    print(m)\n",
        "    X[:, -m:, :] = 0\n",
        "    Xn_t = add_noise(X, 0.00)\n",
        "    Yn_t = add_noise(Y, 0.00)\n",
        "    X_data = {'train': Xn_t[:d_p['M_train']], 'val': Xn_t[d_p['M_train']:-d_p['M_test']], 'test': Xn_t[-d_p['M_test']:]}\n",
        "    Y_data = {'train': Yn_t[:d_p['M_train']], 'val': Yn_t[d_p['M_train']:-d_p['M_test']], 'test': Y[-d_p['M_test']:]}\n",
        "\n",
        "    return X_data, Y_data, sel_GSOs, gsos_idx\n",
        "\n",
        "\n",
        "def get_signals(d_p, GSOs):\n",
        "    range_GSO = np.arange(d_p['min_GSO'], d_p['max_GSO'])\n",
        "    gsos_idx = np.random.choice(range_GSO, size=d_p['n_GSOs'], replace=False)\n",
        "    sel_GSOs = GSOs[gsos_idx]\n",
        "    Yn_t, X_t, Y_t = dagu.create_diff_data(d_p['M'], sel_GSOs, d_p['max_src_node'], d_p['n_p_x'], d_p['n_p_y'],\n",
        "                                           d_p['n_sources'], src_t=d_p['src_t'], torch_tensor=True, verb=False)\n",
        "\n",
        "\n",
        "\n",
        "    X_data = {'train': X_t[:d_p['M_train']], 'val': X_t[d_p['M_train']:-d_p['M_test']], 'test': X_t[-d_p['M_test']:]}\n",
        "    Y_data = {'train': Yn_t[:d_p['M_train']], 'val': Yn_t[d_p['M_train']:-d_p['M_test']],\n",
        "              'test': Y_t[-d_p['M_test']:]}\n",
        "\n",
        "    return X_data, Y_data, sel_GSOs, gsos_idx\n",
        "\n",
        "\n",
        "def run_exp(d_p, d_arc_args, d_mod_p, exps, verb=True):\n",
        "    # Create error variables\n",
        "    err = np.zeros((d_p['n_tries'], len(exps)))\n",
        "    std = np.zeros((d_p['n_tries'], len(exps)))\n",
        "    times = np.zeros((d_p['n_tries'], len(exps)))\n",
        "\n",
        "    t_begin = time.time()\n",
        "    # for i in range(d_p['n_tries']):\n",
        "    with tqdm(total=d_p['n_tries']*len(exps), disable=False) as pbar:\n",
        "        for i in range(d_p['n_tries']):\n",
        "            Adj, W, GSOs, Psi = get_real_data(d_p, get_Psi=True)\n",
        "\n",
        "            X_data, Y_data, sel_GSOs, sel_GSOs_idx = arth(d_p, GSOs)\n",
        "\n",
        "            for j, exp in enumerate(exps):\n",
        "                arc_p = {**exp['arc_p']}\n",
        "\n",
        "                arc_p['args'] = {**d_arc_args, **arc_p['args']} if 'args' in arc_p.keys() else {**d_arc_args}\n",
        "                mod_p = {**d_mod_p, **exp['mod_p']} if 'mod_p' in exp.keys() else d_mod_p\n",
        "\n",
        "                if exp['arc_p']['arch'] == LinDAGRegModel:\n",
        "                    # Fit and test linear model\n",
        "                    if 'transp' in arc_p.keys() and arc_p['transp']:\n",
        "                        dag_T = nx.from_numpy_array(Adj, create_using=nx.DiGraph())\n",
        "                        Psi = np.array([dagu.compute_Dq(dag_T, i, d_p['N']) for i in range(d_p['N'])]).T\n",
        "                        arc_p['transp'] = False\n",
        "\n",
        "                    Psi_sel = utils.select_GSO(arc_p, Psi.T, Psi[:,sel_GSOs_idx].T, W, Adj, sel_GSOs_idx).numpy().T\n",
        "                    lin_model = LinDAGRegModel(W, Psi_sel)\n",
        "                    t_i = time.time()\n",
        "                    lin_model.fit(X_data['train'], Y_data['train'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = lin_model.test(X_data['test'], Y_data['test'])\n",
        "                    params = lin_model.n_params if hasattr(lin_model, 'n_params') else None\n",
        "\n",
        "\n",
        "                elif exp['arc_p']['arch'] == DVAE:\n",
        "                    X_data1 = DVAE_exp(Adj, X_data)\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data1, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data1['test'], Y_data['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "\n",
        "                elif exp['arc_p']['arch'] == DAGNN:\n",
        "                    X_data1, Y_data1 = DAGNN_model(Adj, X_data, Y_data)\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data1, Y_data1, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data1['test'], Y_data1['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "                else:\n",
        "                    # Fit and test nonlinear models\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data['test'], Y_data['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "                times[i,j] = t_e\n",
        "\n",
        "                # params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "                # Progress\n",
        "                pbar.update(1)\n",
        "                if verb:\n",
        "                    print(f'-{i}. {exp[\"leg\"]}: err: {err[i,j]:.3f} | std: {std[i,j]:.3f}  |' +\n",
        "                          f' time: {times[i,j]:.1f} | n_params: {params}')\n",
        "\n",
        "    total_t = (time.time() - t_begin)/60\n",
        "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
        "    return err, std, times\n",
        "\n",
        "\n",
        "\n",
        "Exps = [\n",
        "    # Our Models\n",
        "\n",
        "    # {'arc_p': {'arch': ParallelMLPSum , 'GSO': 'GSOs', 'n_inputs': 25, 'input_dim': 25, 'hidden_dims': [32], 'output_dim': 25}, 'leg': 'ParallelMLPSum - 1 layer, hid_dim:32'},\n",
        "    # {'arc_p': {'arch': SharedMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [32], 'output_dim': 20}, 'leg': 'SharedMLPSum - 1 layer, hid_dim:32'},\n",
        "\n",
        "\n",
        "\n",
        "    # {'arc_p': {'arch': ParallelMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [64], 'output_dim': 20}, 'leg': 'ParallelMLPSum - 1 layer, hid_dim:64'},\n",
        "    # {'arc_p': {'arch': SharedMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [64], 'output_dim': 20}, 'leg': 'SharedMLPSum - 1 layer, hid_dim:64'},\n",
        "\n",
        "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'DCN'},\n",
        "    # {'arc_p': {'arch': SMLP , 'GSO': 'GSOs', 'in_dim': 1, 'hid_dim': [128], 'out_dim': 1, 'bias' : True }, 'leg': 'PDCN-128'},\n",
        "\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'DCN-15'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'DCN-10'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'leg': 'DCN-5'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'DAGConv'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'DAGConv-15'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'DAGConv-10'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'leg': 'DAGConv-5'},\n",
        "\n",
        "\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs', 'transp': True}, 'leg': 'DCN-T'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'DCN-15-T'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10, 'transp': True}, 'leg': 'DCN-10-T'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs', 'transp': True}, 'leg': 'DAGConv-T'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'DAGConv-15-T'},\n",
        "\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'transp': True, 'args': {'mlp_layers': 4}}, 'leg': 'ADCN-4-T'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'transp': True, 'args': {'mlp_layers': 5}}, 'leg': 'ADCN-5-T'},\n",
        "\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'GSOs'}, 'leg': 'Linear'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'Linear-15'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'Linear-10'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'GSOs', 'transp': True}, 'leg': 'Linear-T'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'Linear-15-T'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 10, 'transp': True}, 'leg': 'Linear-10-T'},\n",
        "\n",
        "\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 4}}, 'leg': 'ADCN-4-2'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 5}}, 'leg': 'ADCN-5-2'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 4, 'n_layers': 4}}, 'leg': 'ADCN-4-4'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 5, 'n_layers': 4}}, 'leg': 'ADCN-5-4'},\n",
        "    # {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'leg': 'GNN-A'},\n",
        "\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 2, 'transp': False}, 'leg': 'FB-GCNN-2'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 3, 'transp': False}, 'leg': 'FB-GCNN-3'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 4, 'transp': False}, 'leg': 'FB-GCNN-4'},\n",
        "    # {'arc_p': {'arch': GraphSAGE, 'GSO': 'A-dgl', 'args': {'aggregator': 'mean'}}, 'leg': 'GraphSAGE-A'},\n",
        "    # {'arc_p': {'arch': GIN, 'GSO': 'A-dgl', 'args': {'aggregator': 'sum'}}, 'leg': 'GIN-A'},\n",
        "    # {'arc_p': {'arch': GIN, 'GSO': 'A-dgl', 'args': {'aggregator': 'sum', 'mlp_layers': 4}}, 'leg': 'GIN-A-4'},\n",
        "    # {'arc_p': {'arch': MLP, 'GSO': None}, 'leg': 'MLP'},\n",
        "    # {'arc_p': {'arch': MLP, 'GSO': None, 'args': {'n_layers': 4}}, 'leg': 'MLP-4'},\n",
        "    # {'arc_p': {'arch': GAT, 'GSO': 'A-dgl', 'args': {'num_heads': 2, 'hid_dim': 16, 'gat_params': {'attn_drop': 0}}},\n",
        "    #  'leg': 'GAT'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGNN, 'GSO': 'GSOs', 'emb_dim': 1, 'hidden_dim':128, 'out_dim': 128, 'max_n': 107,'nvt':1 ,\n",
        "    #            'START_TYPE': 0, 'END_TYPE': 1, 'hs':128, 'nz': 128, 'agg': \"attn_h\", 'num_layers':2, 'bidirectional': False, 'out_wx': False, 'out_pool_all': False,\n",
        "    #            'out_pool': P_MAX, 'dropout': 0, 'num_nodes': 107}, 'leg': 'DAGNN'},\n",
        "    # {'arc_p': {'arch': DVAE, 'GSO': 'GSOs','max_n':107, 'nvt':1, 'START_TYPE':0, 'END_TYPE':1, 'hs':128,'nz':107, 'bidirectional': False, 'vid': True}, 'leg': 'DVAE'},\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mod_p_init = default_mod_p.copy()\n",
        "mod_p_init['pat'] = 50\n",
        "verb = True\n",
        "err, std, times = run_exp(data_p, default_arch_args, mod_p_init, Exps, verb=verb)\n",
        "\n",
        "\n",
        "print('err', np.mean(err, axis=0))\n",
        "print('std', np.mean(std, axis=0))\n",
        "print('times', np.mean(times, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "import networkx as nx\n",
        "from tqdm.auto import tqdm\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "from numpy import linalg as la\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "\n",
        "import src.dag_utils as dagu\n",
        "import src.utils as utils\n",
        "from src.arch import DAGConv, FB_DAGConv, SF_DAGConv, ADCN , ParallelMLPSum, SharedMLPSum, SMLP, SAM1\n",
        "from src.models import Model, LinDAGRegModel\n",
        "from src.baselines_archs import GAT, MLP, MyGCNN, GraphSAGE, GIN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"dgl\")\n",
        "import os\n",
        "import igraph as ig\n",
        "from src.utils_Dagnn import *\n",
        "from src.DAGNN import DAGNN, DVAE\n",
        "\n",
        "\n",
        "\n",
        "# Ser random seed\n",
        "SEED = 10\n",
        "PATH = 'results/diffusion/'\n",
        "SAVE = True\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "# dgl.random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# torch.cuda.set_per_process_memory_fraction(.5, device=device)\n",
        "\n",
        "\n",
        "\n",
        "M = 22\n",
        "\n",
        "data_p = {\n",
        "    'n_tries': 25,  #25,\n",
        "\n",
        "    ## Graph parameters\n",
        "    'p': 0.2,  # .2                  # Edge prob in Erdos-Renyi DAG\n",
        "    'N': 107,                    # Number of nodes\n",
        "\n",
        "    ## Signal parameters\n",
        "    'M': M,                   # Number of observed signals\n",
        "    'M_train': int(0.7 * M),  # Samples selected for training\n",
        "    'M_val': int(0.2 * M),    # Samples selected for validation\n",
        "    'M_test': int(0.1 * M),   # Samples selected for test\n",
        "    'src_t': 'constant',          # 'random' or 'constant'\n",
        "    'max_src_node': 15, #25,           # Maximum index of nodes allowed to be sources\n",
        "    'n_sources': 14,             # Maximum Number of source nodes\n",
        "    'n_p_x': .1,\n",
        "    'n_p_y': .1,                 # Normalized noise power\n",
        "    'max_GSO': 50,              # Maximum index of GSOs involved in the diffusion\n",
        "    'min_GSO': 0,               # Minimum index of GSOs involved in the diffusion\n",
        "    'n_GSOs': 20,            # Number of GSOs\n",
        "}\n",
        "\n",
        "default_mod_p = {\n",
        "    'bs': 5,           # Size of the batch\n",
        "    'lr': 5e-3,         # Learning rate\n",
        "    'epochs': 500,  #50,       # Number of training epochs\n",
        "    'pat': 25,  # 15        # Number of non-decreasing epoch to stop training\n",
        "    'wd': 1e-4,         # Weight decay\n",
        "}\n",
        "\n",
        "default_arch_args = {\n",
        "    'in_dim': 1,        # Input dimension\n",
        "    'hid_dim': 32,     # Hidden dimension\n",
        "    'out_dim': 1,       # Output dimension\n",
        "    'n_layers': 2,#2,  # 3 also works well          # Number of layers\n",
        "    'l_act': None,\n",
        "    'bias': True,\n",
        "}\n",
        "\n",
        "\n",
        "def add_noise(signal, n_p):\n",
        "    shape = signal.shape\n",
        "\n",
        "    M = shape[0]\n",
        "    N = shape[1]\n",
        "\n",
        "    if n_p <= 0:\n",
        "        return signal\n",
        "\n",
        "    signal_norm = torch.norm(signal, p=2, dim=1, keepdim=True)\n",
        "    signal_norm[signal_norm == 0] = 1\n",
        "    noise = torch.randn(M, N, 1, device=signal.device)\n",
        "    noise_norm = torch.norm(noise, p=2, dim=1, keepdim=True)\n",
        "    noise = noise * signal_norm * torch.sqrt(torch.tensor(n_p)) / noise_norm\n",
        "\n",
        "    return signal + noise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_real_data(d_dat_p ,get_Psi=False):\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    import numpy as np\n",
        "\n",
        "    Adj = np.load('/content/drive/MyDrive/Gene/A_gene.npy')\n",
        "\n",
        "    W = la.inv(np.eye(d_dat_p['N']) - Adj)\n",
        "    W_inf = la.inv(W)\n",
        "    dag = nx.from_numpy_array(Adj.T, create_using=nx.DiGraph())\n",
        "    if get_Psi:\n",
        "        Psi = np.array([dagu.compute_Dq(dag, i, d_dat_p['N']) for i in range(d_dat_p['N'])]).T\n",
        "        GSOs = np.array([(W * Psi[:,i]) @ W_inf for i in range(d_dat_p['N'])])\n",
        "        return Adj, W, GSOs, Psi\n",
        "\n",
        "    GSOs = np.array([(W * dagu.compute_Dq(dag, i, d_dat_p['N'])) @ W_inf for i in range(d_dat_p['N'])])\n",
        "\n",
        "    return Adj, W, GSOs\n",
        "\n",
        "\n",
        "\n",
        "def arth(d_p, GSOs):\n",
        "\n",
        "    range_GSO = np.arange(d_p['min_GSO'], d_p['max_GSO'])\n",
        "    gsos_idx = np.random.choice(range_GSO, size=d_p['n_GSOs'], replace=False)\n",
        "    sel_GSOs = GSOs[gsos_idx]\n",
        "    Y = torch.from_numpy(np.load('/content/drive/MyDrive/Gene/filtered_expression_data.npy')).float()\n",
        "\n",
        "    X = Y.clone()\n",
        "    X = X.unsqueeze(2)\n",
        "    Y = Y.unsqueeze(2)\n",
        "    m = 80\n",
        "    print(m)\n",
        "    X[:, -m:, :] = 0\n",
        "    Xn_t = add_noise(X, 0.00)\n",
        "    Yn_t = add_noise(Y, 0.00)\n",
        "    X_data = {'train': Xn_t[:d_p['M_train']], 'val': Xn_t[d_p['M_train']:-d_p['M_test']], 'test': Xn_t[-d_p['M_test']:]}\n",
        "    Y_data = {'train': Yn_t[:d_p['M_train']], 'val': Yn_t[d_p['M_train']:-d_p['M_test']], 'test': Y[-d_p['M_test']:]}\n",
        "\n",
        "    return X_data, Y_data, sel_GSOs, gsos_idx\n",
        "\n",
        "\n",
        "def get_signals(d_p, GSOs):\n",
        "    range_GSO = np.arange(d_p['min_GSO'], d_p['max_GSO'])\n",
        "    gsos_idx = np.random.choice(range_GSO, size=d_p['n_GSOs'], replace=False)\n",
        "    sel_GSOs = GSOs[gsos_idx]\n",
        "    Yn_t, X_t, Y_t = dagu.create_diff_data(d_p['M'], sel_GSOs, d_p['max_src_node'], d_p['n_p_x'], d_p['n_p_y'],\n",
        "                                           d_p['n_sources'], src_t=d_p['src_t'], torch_tensor=True, verb=False)\n",
        "\n",
        "\n",
        "\n",
        "    X_data = {'train': X_t[:d_p['M_train']], 'val': X_t[d_p['M_train']:-d_p['M_test']], 'test': X_t[-d_p['M_test']:]}\n",
        "    Y_data = {'train': Yn_t[:d_p['M_train']], 'val': Yn_t[d_p['M_train']:-d_p['M_test']],\n",
        "              'test': Y_t[-d_p['M_test']:]}\n",
        "\n",
        "    return X_data, Y_data, sel_GSOs, gsos_idx\n",
        "\n",
        "\n",
        "def run_exp(d_p, d_arc_args, d_mod_p, exps, verb=True):\n",
        "    # Create error variables\n",
        "    err = np.zeros((d_p['n_tries'], len(exps)))\n",
        "    std = np.zeros((d_p['n_tries'], len(exps)))\n",
        "    times = np.zeros((d_p['n_tries'], len(exps)))\n",
        "\n",
        "    t_begin = time.time()\n",
        "    # for i in range(d_p['n_tries']):\n",
        "    with tqdm(total=d_p['n_tries']*len(exps), disable=False) as pbar:\n",
        "        for i in range(d_p['n_tries']):\n",
        "            Adj, W, GSOs, Psi = get_real_data(d_p, get_Psi=True)\n",
        "\n",
        "            X_data, Y_data, sel_GSOs, sel_GSOs_idx = arth(d_p, GSOs)\n",
        "\n",
        "            for j, exp in enumerate(exps):\n",
        "                arc_p = {**exp['arc_p']}\n",
        "\n",
        "                arc_p['args'] = {**d_arc_args, **arc_p['args']} if 'args' in arc_p.keys() else {**d_arc_args}\n",
        "                mod_p = {**d_mod_p, **exp['mod_p']} if 'mod_p' in exp.keys() else d_mod_p\n",
        "\n",
        "                if exp['arc_p']['arch'] == LinDAGRegModel:\n",
        "                    # Fit and test linear model\n",
        "                    if 'transp' in arc_p.keys() and arc_p['transp']:\n",
        "                        dag_T = nx.from_numpy_array(Adj, create_using=nx.DiGraph())\n",
        "                        Psi = np.array([dagu.compute_Dq(dag_T, i, d_p['N']) for i in range(d_p['N'])]).T\n",
        "                        arc_p['transp'] = False\n",
        "\n",
        "                    Psi_sel = utils.select_GSO(arc_p, Psi.T, Psi[:,sel_GSOs_idx].T, W, Adj, sel_GSOs_idx).numpy().T\n",
        "                    lin_model = LinDAGRegModel(W, Psi_sel)\n",
        "                    t_i = time.time()\n",
        "                    lin_model.fit(X_data['train'], Y_data['train'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = lin_model.test(X_data['test'], Y_data['test'])\n",
        "                    params = lin_model.n_params if hasattr(lin_model, 'n_params') else None\n",
        "\n",
        "\n",
        "                elif exp['arc_p']['arch'] == DVAE:\n",
        "                    X_data1 = DVAE_exp(Adj, X_data)\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data1, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data1['test'], Y_data['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "\n",
        "                elif exp['arc_p']['arch'] == DAGNN:\n",
        "                    X_data1, Y_data1 = DAGNN_model(Adj, X_data, Y_data)\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data1, Y_data1, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data1['test'], Y_data1['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "                else:\n",
        "                    # Fit and test nonlinear models\n",
        "                    GSO = utils.select_GSO(arc_p, GSOs, sel_GSOs, W, Adj)\n",
        "                    K = GSO.shape[0] if isinstance(GSO, torch.Tensor) and len(GSO.shape) == 3 else 0\n",
        "                    arch = utils.instantiate_arch(arc_p, K)\n",
        "                    model = Model(arch, device=device)\n",
        "                    t_i = time.time()\n",
        "                    model.fit(X_data, Y_data, GSO, mod_p['lr'], mod_p['epochs'], mod_p['bs'], mod_p['wd'], patience=mod_p['pat'])\n",
        "                    t_e = time.time() - t_i\n",
        "                    err[i,j], std[i,j] = model.test(X_data['test'], Y_data['test'], GSO)\n",
        "                    params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "                times[i,j] = t_e\n",
        "\n",
        "                # params = arch.n_params if hasattr(arch, 'n_params') else None\n",
        "\n",
        "                # Progress\n",
        "                pbar.update(1)\n",
        "                if verb:\n",
        "                    print(f'-{i}. {exp[\"leg\"]}: err: {err[i,j]:.3f} | std: {std[i,j]:.3f}  |' +\n",
        "                          f' time: {times[i,j]:.1f} | n_params: {params}')\n",
        "\n",
        "    total_t = (time.time() - t_begin)/60\n",
        "    print(f'----- Ellapsed time: {total_t:.2f} minutes -----')\n",
        "    return err, std, times\n",
        "\n",
        "\n",
        "\n",
        "Exps = [\n",
        "    # Our Models\n",
        "\n",
        "    # {'arc_p': {'arch': ParallelMLPSum , 'GSO': 'GSOs', 'n_inputs': 25, 'input_dim': 25, 'hidden_dims': [32], 'output_dim': 25}, 'leg': 'ParallelMLPSum - 1 layer, hid_dim:32'},\n",
        "    # {'arc_p': {'arch': SharedMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [32], 'output_dim': 20}, 'leg': 'SharedMLPSum - 1 layer, hid_dim:32'},\n",
        "\n",
        "\n",
        "\n",
        "    # {'arc_p': {'arch': ParallelMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [64], 'output_dim': 20}, 'leg': 'ParallelMLPSum - 1 layer, hid_dim:64'},\n",
        "    # {'arc_p': {'arch': SharedMLPSum , 'GSO': 'GSOs', 'n_inputs': 20, 'input_dim': 20, 'hidden_dims': [64], 'output_dim': 20}, 'leg': 'SharedMLPSum - 1 layer, hid_dim:64'},\n",
        "\n",
        "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs'}, 'leg': 'DCN'},\n",
        "    {'arc_p': {'arch': SMLP , 'GSO': 'GSOs', 'in_dim': 1, 'hid_dim': [128], 'out_dim': 1, 'bias' : True }, 'leg': 'PDCN-128'},\n",
        "\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'DCN-15'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'DCN-10'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'leg': 'DCN-5'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs'}, 'leg': 'DAGConv'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'DAGConv-15'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'DAGConv-10'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 5}, 'leg': 'DAGConv-5'},\n",
        "\n",
        "\n",
        "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'GSOs', 'transp': True}, 'leg': 'DCN-T'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'DCN-15-T'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 10, 'transp': True}, 'leg': 'DCN-10-T'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'GSOs', 'transp': True}, 'leg': 'DAGConv-T'},\n",
        "    # {'arc_p': {'arch': DAGConv, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'DAGConv-15-T'},\n",
        "\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'transp': True, 'args': {'mlp_layers': 4}}, 'leg': 'ADCN-4-T'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'transp': True, 'args': {'mlp_layers': 5}}, 'leg': 'ADCN-5-T'},\n",
        "\n",
        "    {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'GSOs'}, 'leg': 'Linear'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 15}, 'leg': 'Linear-15'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 10}, 'leg': 'Linear-10'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'GSOs', 'transp': True}, 'leg': 'Linear-T'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 15, 'transp': True}, 'leg': 'Linear-15-T'},\n",
        "    # {'arc_p': {'arch': LinDAGRegModel, 'GSO': 'rnd_GSOs', 'n_gsos': 10, 'transp': True}, 'leg': 'Linear-10-T'},\n",
        "\n",
        "\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 4}}, 'leg': 'ADCN-4-2'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 5}}, 'leg': 'ADCN-5-2'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 4, 'n_layers': 4}}, 'leg': 'ADCN-4-4'},\n",
        "    # {'arc_p': {'arch': ADCN, 'GSO': 'GSOs', 'args': {'mlp_layers': 5, 'n_layers': 4}}, 'leg': 'ADCN-5-4'},\n",
        "    {'arc_p': {'arch': MyGCNN, 'GSO': 'A'}, 'leg': 'GNN-A'},\n",
        "\n",
        "    {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 2, 'transp': False}, 'leg': 'FB-GCNN-2'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 3, 'transp': False}, 'leg': 'FB-GCNN-3'},\n",
        "    # {'arc_p': {'arch': FB_DAGConv, 'GSO': 'A_pows', 'K': 4, 'transp': False}, 'leg': 'FB-GCNN-4'},\n",
        "    {'arc_p': {'arch': GraphSAGE, 'GSO': 'A-dgl', 'args': {'aggregator': 'mean'}}, 'leg': 'GraphSAGE-A'},\n",
        "    {'arc_p': {'arch': GIN, 'GSO': 'A-dgl', 'args': {'aggregator': 'sum'}}, 'leg': 'GIN-A'},\n",
        "    {'arc_p': {'arch': GIN, 'GSO': 'A-dgl', 'args': {'aggregator': 'sum', 'mlp_layers': 4}}, 'leg': 'GIN-A-4'},\n",
        "    {'arc_p': {'arch': MLP, 'GSO': None}, 'leg': 'MLP'},\n",
        "    # {'arc_p': {'arch': MLP, 'GSO': None, 'args': {'n_layers': 4}}, 'leg': 'MLP-4'},\n",
        "    {'arc_p': {'arch': GAT, 'GSO': 'A-dgl', 'args': {'num_heads': 2, 'hid_dim': 16, 'gat_params': {'attn_drop': 0}}},\n",
        "     'leg': 'GAT'},\n",
        "\n",
        "    # {'arc_p': {'arch': DAGNN, 'GSO': 'GSOs', 'emb_dim': 1, 'hidden_dim':128, 'out_dim': 128, 'max_n': 107,'nvt':1 ,\n",
        "    #            'START_TYPE': 0, 'END_TYPE': 1, 'hs':128, 'nz': 128, 'agg': \"attn_h\", 'num_layers':2, 'bidirectional': False, 'out_wx': False, 'out_pool_all': False,\n",
        "    #            'out_pool': P_MAX, 'dropout': 0, 'num_nodes': 107}, 'leg': 'DAGNN'},\n",
        "    # {'arc_p': {'arch': DVAE, 'GSO': 'GSOs','max_n':107, 'nvt':1, 'START_TYPE':0, 'END_TYPE':1, 'hs':128,'nz':107, 'bidirectional': False, 'vid': True}, 'leg': 'DVAE'},\n",
        "\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mod_p_init = default_mod_p.copy()\n",
        "mod_p_init['pat'] = 50\n",
        "verb = True\n",
        "err, std, times = run_exp(data_p, default_arch_args, mod_p_init, Exps, verb=verb)\n",
        "\n",
        "\n",
        "print('err', np.mean(err, axis=0))\n",
        "print('std', np.mean(std, axis=0))\n",
        "print('times', np.mean(times, axis=0))"
      ],
      "metadata": {
        "id": "kK4jI80YVigx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}